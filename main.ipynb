{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc3edb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-display\n",
    "# %%capture, hides output of this cell. When cell fails to run remove capture to check error\n",
    "%pip install -r requirements.txt;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23b2888",
   "metadata": {},
   "source": [
    "### Welcome\n",
    "Welcome to the main program. We worked with python 3.12.2 and used the packages specified in the requirements.txt. You can install them using the cell above. If this doesn't work try making a new virtual environment first.\n",
    "\n",
    "This notebook has the following cells\n",
    "- Parameter file and dataset selection\n",
    "- Dataset and parameter file loading\n",
    "- Ground truth, prediction, and feature selection\n",
    "- Metric selection\n",
    "- Calculations and Results\n",
    "- Saving parameters to file\n",
    "\n",
    "It is recommended to run each cell and fill out the selections before running the next cell. There should be no need to change any code, all of the selection is done by [ipywidgets](https://ipywidgets.readthedocs.io/en/latest/how-to/index.html). The cells of the notebook can be closed by dubble clicking at the left edge of a cell. \n",
    "\n",
    "\n",
    "If you posses the model used you may also use SHAP to find the feature importance of the model. In the file, [shap fairness_explainer](https://github.com/bytnater/bias-analyse/blob/main/fairness_metrics/Fairness_explainer/shap_fairness_explainer.py), there is a example on how to use this modul.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92de094d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import os\n",
    "from IPython.display import display\n",
    "\n",
    "import warnings\n",
    "import torch\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import Layout, Box, VBox, Accordion, Label, Valid, Text, IntText, Combobox, Checkbox, RadioButtons, Button\n",
    "\n",
    "## part of the project\n",
    "from fairness_metrics.Predicted_outcomes.Error_rate_metrics import Error_rate_metrics\n",
    "from fairness_metrics.Predicted_outcomes.Predictive_value_metrics import Predictive_value_metrics\n",
    "from fairness_metrics.Predicted_outcomes.statistical_parity import statistical_parity\n",
    "from fairness_metrics.predicted_probs.balance_in_pos_neg import balance_in_pos_neg\n",
    "from fairness_metrics.predicted_probs.well_callibrated import well_calibration\n",
    "from fairness_metrics.similarity_based.similarity_based import LipschitzFairness\n",
    "\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16402f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input file selection\n",
    "USE_PRESET= RadioButtons(\n",
    "    options=[('Load file', 1), ('Create new', 0)],\n",
    "    value=0,\n",
    "    style = {'description_width': 'initial'},\n",
    "    description='Load params file:',\n",
    ")\n",
    "INPUT_FILE_NAME = Text(\n",
    "    placeholder='Type file name for parameters',\n",
    "    description='File name:',\n",
    "    tooltip='do not forget the file extension'\n",
    ")\n",
    "PRESET_FILENAME = INPUT_FILE_NAME.value if INPUT_FILE_NAME.value else 'No file'\n",
    "file_exits = os.path.exists(utils.SAVED_PRESET_PATH + PRESET_FILENAME)\n",
    "FILE_FOUND = Valid(\n",
    "    value=file_exits,\n",
    "    style = {'description_width': 'initial'},\n",
    "    description=f'Preset file \"{PRESET_FILENAME}\"',\n",
    "    tooltip='Indicates if the chosen file has been found'\n",
    ")\n",
    "FILE_INFO_BOX = VBox([\n",
    "    Label(value=f'Select your params file here, They must be in the folder \"{utils.SAVED_PRESET_PATH}\"'),\n",
    "    INPUT_FILE_NAME,\n",
    "    FILE_FOUND,\n",
    "])\n",
    "FILE_INFO_BOX.layout.display = 'none'\n",
    "\n",
    "INPUT_DATASET_NAME = Text(\n",
    "    placeholder='Type file name for dataset',\n",
    "    description='File name:',\n",
    "    tooltip='do not forget the file extension'\n",
    ")\n",
    "PRESET_DATASET_FILENAME = INPUT_DATASET_NAME.value if INPUT_DATASET_NAME.value else 'No file'\n",
    "file_exits = os.path.exists(utils.SAVED_PRESET_PATH + PRESET_DATASET_FILENAME)\n",
    "DATASET_FOUND = Valid(\n",
    "    value=file_exits,\n",
    "    style = {'description_width': 'initial'},\n",
    "    description=f'Preset file \"{PRESET_DATASET_FILENAME}\"',\n",
    "    tooltip='Indicates if the chosen file has been found'\n",
    ")\n",
    "\n",
    "\n",
    "info_box = VBox([\n",
    "    USE_PRESET,\n",
    "    FILE_INFO_BOX,\n",
    "    Label(value=f'Select your dataset file here, They must be in the folder \"{utils.SAVED_DATASET_PATH}\"'),\n",
    "    INPUT_DATASET_NAME,\n",
    "    DATASET_FOUND,\n",
    "])\n",
    "\n",
    "output_file_selection = widgets.Output()\n",
    "display(info_box, output_file_selection)\n",
    "\n",
    "def update_file_name_info(_):\n",
    "    with output_file_selection:\n",
    "        PRESET_FILENAME = INPUT_FILE_NAME.value if INPUT_FILE_NAME.value else 'No file'\n",
    "        file_exits = os.path.exists(os.path.join(utils.SAVED_PRESET_PATH + PRESET_FILENAME))\n",
    "        FILE_FOUND.description = f'Preset file \"{PRESET_FILENAME}\"'\n",
    "        FILE_FOUND.value = file_exits\n",
    "        if file_exits and INPUT_FILE_NAME.value.endswith('.pt'):\n",
    "            params = torch.load(utils.SAVED_PRESET_PATH + INPUT_FILE_NAME.value, weights_only=True)\n",
    "            INPUT_DATASET_NAME.value = params.get('used_dataset', '')\n",
    "\n",
    "def update_dataset_info(_):\n",
    "    with output_file_selection:\n",
    "        PRESET_FILENAME = INPUT_DATASET_NAME.value if INPUT_DATASET_NAME.value else 'No file'\n",
    "        file_exits = os.path.exists(os.path.join(utils.SAVED_DATASET_PATH + PRESET_FILENAME))\n",
    "        DATASET_FOUND.description = f'Preset file \"{PRESET_FILENAME}\"'\n",
    "        DATASET_FOUND.value = file_exits\n",
    "\n",
    "def toggle_visibility(_):\n",
    "    with output_file_selection:\n",
    "        FILE_INFO_BOX.layout.display = 'block' if USE_PRESET.value else 'none'    \n",
    "\n",
    "\n",
    "USE_PRESET.on_trait_change(toggle_visibility)\n",
    "INPUT_FILE_NAME.on_trait_change(update_file_name_info)\n",
    "INPUT_DATASET_NAME.on_trait_change(update_dataset_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25981db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data and file loading\n",
    "dataset = utils.Dataset(utils.SAVED_DATASET_PATH + INPUT_DATASET_NAME.value)\n",
    "display(Label(value=f'dataset at \"{utils.SAVED_DATASET_PATH + INPUT_DATASET_NAME.value}\" has been loaded'))\n",
    "\n",
    "params = {}\n",
    "if USE_PRESET.value:\n",
    "    params = torch.load(utils.SAVED_PRESET_PATH + INPUT_FILE_NAME.value, weights_only=True)\n",
    "\n",
    "    display(Label(value=f'\"{INPUT_FILE_NAME.value}\" has been loaded'))\n",
    "\n",
    "params['used_dataset'] = INPUT_DATASET_NAME.value\n",
    "torch.save(params, utils.SAVED_PRESET_PATH + utils.RESEVERD_PRESET)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b632587",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ground truth, prediction, and protected atrributes selection\n",
    "params = torch.load(utils.SAVED_PRESET_PATH + utils.RESEVERD_PRESET, weights_only=True)\n",
    "\n",
    "style = {'background':'white'}\n",
    "item_layout = Layout(width='auto')\n",
    "\n",
    "protected_items = [Checkbox(layout=item_layout, description=dataset.i2c[i], indent=False, style=style) for i in range(len(dataset.i2c))]\n",
    "\n",
    "box_layout = Layout(overflow='hidden scroll',\n",
    "                    border='empty',\n",
    "                    width='auto',\n",
    "                    height='300px',\n",
    "                    flex_flow='column',\n",
    "                    display='flex',\n",
    "                    padding='0')\n",
    "\n",
    "PROTECTED_SELECTION = Box(children=protected_items, layout=box_layout)\n",
    "GROUND_SELECTION = Combobox(\n",
    "    value=None,\n",
    "    placeholder='Choose a feature',\n",
    "    options=dataset.i2c+[''],\n",
    "    description='Ground truth:',\n",
    "    ensure_option=True,\n",
    "    style={'description_width':'150px'},\n",
    "    layout=Layout(width='auto'),\n",
    ")\n",
    "PREDICTED_SELECTION = Combobox(\n",
    "    value=None,\n",
    "    placeholder='Choose a feature',\n",
    "    options=dataset.i2c+[''],\n",
    "    description='Predicted by model:',\n",
    "    ensure_option=True,\n",
    "    style={'description_width':'150px'},\n",
    "    layout=Layout(width='auto'),\n",
    ")\n",
    "FEEDBACK_INFO_SLECETION = Label(\n",
    "    value='',\n",
    ")\n",
    "\n",
    "SELECTION_BOX = VBox([\n",
    "    Label('Please select the ground truth and the predicted probability (if available):'), \n",
    "    GROUND_SELECTION,\n",
    "    PREDICTED_SELECTION,\n",
    "    FEEDBACK_INFO_SLECETION,\n",
    "    Label('Please, select the protected attributes you want to analyse:'), \n",
    "    PROTECTED_SELECTION,\n",
    "    ])\n",
    "\n",
    "## Restore data\n",
    "preset_protected_values = params.get('protected_values', torch.zeros(len(dataset.i2c), dtype=bool))\n",
    "for item, value in zip(protected_items, preset_protected_values):\n",
    "    item.value = bool(value)\n",
    "GROUND_SELECTION.value=params.get('ground_truth_column', '')\n",
    "PREDICTED_SELECTION.value=params.get('prediction_column', '')\n",
    "\n",
    "output_selection = widgets.Output()\n",
    "display(SELECTION_BOX, output_selection)\n",
    "\n",
    "def update_selection_feedback(id):\n",
    "    with output_selection:\n",
    "        if GROUND_SELECTION.value == PREDICTED_SELECTION.value != '':\n",
    "            FEEDBACK_INFO_SLECETION.value=f'Both are now selected as \"{GROUND_SELECTION.value}\", Please make sure that the ground truth is not the same as the predictions'\n",
    "        else:\n",
    "            FEEDBACK_INFO_SLECETION.value='You have selected ' + (f'ground truth as \"{GROUND_SELECTION.value}\"' if GROUND_SELECTION.value else 'no ground truth') + ' and ' + (f'predictions as \"{PREDICTED_SELECTION.value}\"' if PREDICTED_SELECTION.value else 'no predictions')\n",
    "\n",
    "GROUND_SELECTION.on_trait_change(update_selection_feedback)\n",
    "PREDICTED_SELECTION.on_trait_change(update_selection_feedback)\n",
    "SELECTION_BOX.on_widget_constructed(update_selection_feedback)\n",
    "\n",
    "SAVE_CHANGES = Button(\n",
    "    description='Save changes',\n",
    "    button_style='success',\n",
    "    tooltip='Save your current selection',\n",
    ")\n",
    "output_save_changes = widgets.Output()\n",
    "\n",
    "def save_changes(id):\n",
    "    with output_save_changes:\n",
    "        params['protected_values'] = torch.tensor([protected_item.value for protected_item in protected_items])\n",
    "        params['ground_truth_column'] = GROUND_SELECTION.value\n",
    "        params['prediction_column'] = PREDICTED_SELECTION.value\n",
    "        torch.save(params, utils.SAVED_PRESET_PATH + utils.RESEVERD_PRESET)\n",
    "\n",
    "SAVE_CHANGES.on_click(save_changes)\n",
    "\n",
    "display(SAVE_CHANGES, output_save_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cda1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metric selection\n",
    "params = torch.load(utils.SAVED_PRESET_PATH + utils.RESEVERD_PRESET, weights_only=True)\n",
    "\n",
    "assert sum(params.get('protected_values', torch.zeros(len(dataset.i2c), dtype=bool))) != 0, 'You have to select at least one protected attribute'\n",
    "\n",
    "\n",
    "# Style and layout\n",
    "item_layout = Layout(width='auto')\n",
    "slider_style = {'description_width': '200px'}\n",
    "\n",
    "# Descriptions\n",
    "fairness_groups_names = [\n",
    "    'Predicted and actual outcomes',\n",
    "    'Predicted probibilities and actual outcomes',\n",
    "    'Causal Discrimination',\n",
    "    'Causal Reasoning'\n",
    "]\n",
    "\n",
    "metric_names = [\n",
    "    ['Error rate', 'Predictive value', 'Statistical parity'],\n",
    "    ['Test-fairness', 'Balance in classes'],\n",
    "    ['Lipschitz']\n",
    "]\n",
    "\n",
    "# Valid widgets\n",
    "VALID_GROUND = Valid(value=True, description='Ground truth')\n",
    "VALID_PRED = Valid(value=True, description='Prediction')\n",
    "\n",
    "# Load slider cache: tag -> slider\n",
    "slider_cache = {\n",
    "    name:widgets.FloatSlider(\n",
    "        value=value,\n",
    "        min=0.1, max=5, step=0.1,\n",
    "        description=name,\n",
    "        tooltip=name,\n",
    "        layout=item_layout,\n",
    "        indent=False,\n",
    "        style=slider_style)\n",
    "    for name, value in params.get('condition', dict()).items()\n",
    "}\n",
    "\n",
    "# Tag selector\n",
    "value = [name for (name, slider) in slider_cache.items()]\n",
    "tags = widgets.TagsInput(\n",
    "    value=value,\n",
    "    allowed_tags=dataset.i2c,\n",
    "    allow_duplicates=False\n",
    ")\n",
    "\n",
    "# Container for the sliders\n",
    "box_layout = Layout(\n",
    "    overflow='hidden scroll',\n",
    "    border='empty',\n",
    "    width='auto',\n",
    "    max_height='300px',\n",
    "    flex_flow='column',\n",
    "    display='flex',\n",
    "    padding='0'\n",
    ")\n",
    "\n",
    "children = [slider for (name, slider) in slider_cache.items()]\n",
    "TAGS_SLIDERS = Box(children=children, layout=box_layout)\n",
    "\n",
    "# TAG_Wrapper for display\n",
    "TAG_WRAPPER = VBox([\n",
    "    tags,\n",
    "    TAGS_SLIDERS,\n",
    "])\n",
    "\n",
    "# Dynamic update function\n",
    "def update_tags_sliders(change):\n",
    "    if change['name'] == 'value':\n",
    "        current_tags = change['new']\n",
    "        new_sliders = []\n",
    "\n",
    "        for name in current_tags:\n",
    "            if name in slider_cache:\n",
    "                slider = slider_cache[name]\n",
    "            else:\n",
    "                slider = widgets.FloatSlider(\n",
    "                    value=1.0,\n",
    "                    min=0.1, max=5, step=0.1,\n",
    "                    description=name,\n",
    "                    tooltip=name,\n",
    "                    layout=item_layout,\n",
    "                    indent=False,\n",
    "                    style=slider_style,\n",
    "                )\n",
    "                slider_cache[name] = slider\n",
    "\n",
    "            new_sliders.append(slider)\n",
    "\n",
    "        TAGS_SLIDERS.children = new_sliders\n",
    "\n",
    "# Observe changes to the tags input\n",
    "tags.observe(update_tags_sliders, names='value')\n",
    "\n",
    "\n",
    "# Metric widgets\n",
    "TEST_FAIRNESS = VBox([\n",
    "    Checkbox(layout=item_layout, value=True, description='Use metric?', indent=False),\n",
    "    Label(value='This metric check if individuals assigned the same score s have equal likelihoods of the positive outcome, independent of the protected attribute'),\n",
    "    VBox([VALID_GROUND, VALID_PRED]),\n",
    "])\n",
    "\n",
    "BALANCE_IN_CLASS = VBox([\n",
    "    Checkbox(layout=item_layout, value=True, description='Use metric?', indent=False),\n",
    "    Label(value='Balance for the positive and negative classes are fairness criteria that focus on ensuring equitable scoring among individuals who share the same actual outcome.'),\n",
    "    Checkbox(layout=item_layout, description='Show the positive balance', indent=False),\n",
    "    Checkbox(layout=item_layout, description='Show the negative balance', indent=False),\n",
    "    VBox([VALID_GROUND, VALID_PRED]),\n",
    "])\n",
    "\n",
    "ERROR_RATE_METRICS = VBox([\n",
    "    Checkbox(layout=item_layout, value=True, description='Use metric?', indent=False),\n",
    "    Label(value='Please, make a selections'),\n",
    "    VBox([VALID_GROUND, VALID_PRED]),\n",
    "])\n",
    "\n",
    "PREDICTIVE_VALUE_METRICS = VBox([\n",
    "    Checkbox(layout=item_layout, value=True, description='Use metric?', indent=False),\n",
    "    Label(value='Please, make a selections'),\n",
    "    VBox([VALID_GROUND, VALID_PRED]),\n",
    "])\n",
    "\n",
    "STATISTICAL_PARITY = VBox([\n",
    "    Checkbox(layout=item_layout, value=True, description='Use metric?', indent=False),\n",
    "    Label(value='Please, make a selections'),\n",
    "    TAG_WRAPPER,\n",
    "    VBox([VALID_PRED]),\n",
    "])\n",
    "\n",
    "SIMILARITY_BASED = VBox([\n",
    "    Checkbox(layout=item_layout, value=True, description='Use metric?', indent=False),\n",
    "    Label(value='Please, make a selections'),\n",
    "    IntText(value=1000, description='Sample size:'),\n",
    "    RadioButtons(options=['Manhattan Distance', 'Euclidean Distance', 'cosine'],\n",
    "                 value='Manhattan Distance',\n",
    "                 style={'description_width': 'initial'},\n",
    "                 description='Choose distance metric:'),\n",
    "    VBox([VALID_PRED]),\n",
    "])\n",
    "\n",
    "# Define metrics\n",
    "metrics_groups = [\n",
    "    [ERROR_RATE_METRICS, PREDICTIVE_VALUE_METRICS, STATISTICAL_PARITY],\n",
    "    [TEST_FAIRNESS, BALANCE_IN_CLASS],\n",
    "    [SIMILARITY_BASED]\n",
    "]\n",
    "\n",
    "# Utility to simulate an accordion group with multi-open toggle buttons\n",
    "def make_toggle_section(title, content):\n",
    "    toggle = widgets.ToggleButton(value=False, description=title, layout=Layout(width='200px'))\n",
    "    box = VBox([content])\n",
    "    box.layout.display = 'block'\n",
    "\n",
    "    def toggle_visibility(change):\n",
    "        box.layout.display = 'none' if change['new'] else 'block'\n",
    "\n",
    "    toggle.observe(toggle_visibility, names='value')\n",
    "    return VBox([toggle, box])\n",
    "\n",
    "# Apply toggle accordion logic to each metrics group\n",
    "custom_groups = []\n",
    "for group_metrics, titles in zip(metrics_groups, metric_names):\n",
    "    group_box = VBox([\n",
    "        make_toggle_section(title, content)\n",
    "        for title, content in zip(titles, group_metrics)\n",
    "    ])\n",
    "    custom_groups.append(group_box)\n",
    "\n",
    "# Create outer accordion using standard ipywidgets (since you only want one top-level group open)\n",
    "outer_accordion = Accordion(children=custom_groups)\n",
    "for i, title in enumerate(fairness_groups_names[:len(custom_groups)]):\n",
    "    outer_accordion.set_title(i, title)\n",
    "\n",
    "# Disables metric that are not usable with the current selection\n",
    "def validate_valid_valids(metric_widgets):\n",
    "    valid_valids = all(v.value for v in metric_widgets.children[-1].children)\n",
    "    metric_widgets.children[0].value = valid_valids\n",
    "    metric_widgets.children[0].disabled = not(valid_valids)\n",
    "\n",
    "# Restore state\n",
    "VALID_GROUND.value = bool(params.get('ground_truth_column', ''))\n",
    "VALID_PRED.value = bool(params.get('prediction_column', ''))\n",
    "\n",
    "[[validate_valid_valids(metric) for metric in group] for group in metrics_groups] \n",
    "\n",
    "default = [[metric.children[0].value for metric in group] for group in metrics_groups]\n",
    "metric_selection = params.get('metric_selection', default)\n",
    "for group, group_selection in zip(metrics_groups, metric_selection):\n",
    "    for metric, selection in zip(group, group_selection):\n",
    "        if not metric.children[0].disabled:\n",
    "            metric.children[0].value = selection\n",
    "\n",
    "BALANCE_IN_CLASS.children[2].value = params.get('balance_pos', True)\n",
    "BALANCE_IN_CLASS.children[3].value = params.get('balance_neg', True)\n",
    "SIMILARITY_BASED.children[2].value = params.get('sample_limit', 1000)\n",
    "SIMILARITY_BASED.children[3].value = params.get('distance_metric', 'Manhattan Distance')\n",
    "\n",
    "# Display the result\n",
    "display(outer_accordion)\n",
    "\n",
    "# Save parameters button\n",
    "SAVE_CHANGES = Button(\n",
    "    description='Save changes',\n",
    "    button_style='success',\n",
    "    tooltip='Save your current selection',\n",
    ")\n",
    "output_save_changes = widgets.Output()\n",
    "\n",
    "def save_changes(id):\n",
    "    with output_save_changes:\n",
    "        params['metric_selection'] = [[metric.children[0].value for metric in group] for group in metrics_groups]\n",
    "        params['balance_pos'] = BALANCE_IN_CLASS.children[2].value\n",
    "        params['balance_neg'] = BALANCE_IN_CLASS.children[3].value\n",
    "        params['sample_limit'] = SIMILARITY_BASED.children[2].value\n",
    "        params['distance_metric'] = SIMILARITY_BASED.children[3].value\n",
    "        params['condition'] = {slider.description:slider.value for slider in TAGS_SLIDERS.children}\n",
    "        torch.save(params, utils.SAVED_PRESET_PATH + utils.RESEVERD_PRESET)\n",
    "\n",
    "SAVE_CHANGES.on_click(save_changes)\n",
    "\n",
    "display(SAVE_CHANGES, output_save_changes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af0fbcd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading and calculating each metric \n",
    "params = torch.load(utils.SAVED_PRESET_PATH + utils.RESEVERD_PRESET, weights_only=True)\n",
    "\n",
    "def flatten(xss):\n",
    "    return [x for xs in xss for x in xs]\n",
    "\n",
    "metrics = [[Error_rate_metrics, Predictive_value_metrics, statistical_parity],\n",
    "           [well_calibration, balance_in_pos_neg],\n",
    "           [LipschitzFairness]]\n",
    "\n",
    "default = [[metric.children[0].value for metric in group] for group in metrics_groups]\n",
    "metric_selection = params.get('metric_selection', default)\n",
    "used_metrics = []\n",
    "for metric, metric_name, selection in zip(flatten(metrics), flatten(metric_names), flatten(metric_selection)):\n",
    "    if selection:\n",
    "        used_metrics.append((metric(dataset, params), metric_name))\n",
    "        print(f'{metric_name} calculated')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b06b98ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show results of each metric\n",
    "for metric, metric_name in used_metrics:\n",
    "    print(f'{'#' * (len(metric_name) + 11)}\\n# Metric {metric_name} #\\n{'#' * (len(metric_name) + 11)}')\n",
    "    for image in metric.show():\n",
    "        image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949e8a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving parameters to file\n",
    "OUTPUT_FILE_NAME = Text(\n",
    "    placeholder='Type output file name',\n",
    "    description='File name:',\n",
    "    tooltip='do not forget the file extension'\n",
    ")\n",
    "FEEDBACK_INFO = Label(\n",
    "    value='',\n",
    ")\n",
    "SUBMIT_BUTTON = Button(\n",
    "    description='Save preset',\n",
    "    disabled=True,\n",
    "    button_style='danger',\n",
    "    tooltip='No file name',\n",
    ")\n",
    "\n",
    "info_box = VBox([\n",
    "    Label(value=f'Select a name for your preset file here, This will be saved in the folder \"{utils.SAVED_PRESET_PATH}\"'),\n",
    "    OUTPUT_FILE_NAME,\n",
    "    SUBMIT_BUTTON,\n",
    "    FEEDBACK_INFO,\n",
    "])\n",
    "\n",
    "output_savefile = widgets.Output()\n",
    "display(info_box, output_savefile)\n",
    "\n",
    "\n",
    "def update_file_name_info(id):\n",
    "    with output_savefile:\n",
    "        if type(id) == Button:\n",
    "            params = torch.load(utils.SAVED_PRESET_PATH + utils.RESEVERD_PRESET, weights_only=True)\n",
    "\n",
    "            torch.save(params, utils.SAVED_PRESET_PATH + OUTPUT_FILE_NAME.value)\n",
    "            FEEDBACK_INFO.value=f'Preset saved to \"{OUTPUT_FILE_NAME.value}\"'\n",
    "        \n",
    "        if type(id) == Text:\n",
    "            FEEDBACK_INFO.value=''\n",
    "        \n",
    "        file_exits = os.path.exists(utils.SAVED_PRESET_PATH + OUTPUT_FILE_NAME.value)\n",
    "        if OUTPUT_FILE_NAME.value == '':\n",
    "            SUBMIT_BUTTON.button_style='danger'\n",
    "            SUBMIT_BUTTON.tooltip='No file name'\n",
    "            SUBMIT_BUTTON.disabled=True\n",
    "        elif OUTPUT_FILE_NAME.value == 'session_save.pt':\n",
    "            SUBMIT_BUTTON.button_style='danger'\n",
    "            SUBMIT_BUTTON.tooltip='This file name is reserved'\n",
    "            SUBMIT_BUTTON.disabled=True\n",
    "        elif not OUTPUT_FILE_NAME.value.endswith('.pt'):\n",
    "            SUBMIT_BUTTON.button_style='warning'\n",
    "            SUBMIT_BUTTON.tooltip='Please make it a .pt file'\n",
    "            SUBMIT_BUTTON.disabled=False\n",
    "        elif file_exits:\n",
    "            SUBMIT_BUTTON.button_style='info'\n",
    "            SUBMIT_BUTTON.tooltip='A file already exists with this name, overwrite is possible'\n",
    "            SUBMIT_BUTTON.disabled=False\n",
    "        else:\n",
    "            SUBMIT_BUTTON.button_style='success'\n",
    "            SUBMIT_BUTTON.tooltip='Save file'\n",
    "            SUBMIT_BUTTON.disabled=False\n",
    "\n",
    "        \n",
    "OUTPUT_FILE_NAME.on_trait_change(update_file_name_info)\n",
    "SUBMIT_BUTTON.on_click(update_file_name_info)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
